{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7Y0teSrslN2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a9e779c-3a6d-4211-a5ee-5e8a26bea05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data download\n",
        "# kaggle: https://www.kaggle.com/datasets/marklvl/sentiment-labelled-sentences-data-set\n",
        "\n",
        "!wget -q --show-progress https://raw.githubusercontent.com/rambabar/NLP/main/data/ford_sentence_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG8oS5JZYQ0x",
        "outputId": "b5c49388-4e2d-4f34-90e5-663c7a67e26e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rford_sentence_data.   0%[                    ]       0  --.-KB/s               \rford_sentence_data. 100%[===================>]   2.92M  --.-KB/s    in 0.07s   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!unzip /content/sentiment_labelled_sentences.zip -d /content/data"
      ],
      "metadata": {
        "id": "PLESwuLLX0nD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8777a1b4-ae29-47b7-b025-2b7cd80cb16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/sentiment_labelled_sentences.zip, /content/sentiment_labelled_sentences.zip.zip or /content/sentiment_labelled_sentences.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # If Training time of model is more to prevent disconnect\n",
        "# #Just open Chrome DevTools by pressing F12 or Ctrl+Shift+I on Linux & run following JavaScript code in your console:\n",
        "# '''\n",
        "# function KeepClicking(){\n",
        "#    console.log(\"Clicking\");\n",
        "#    document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "# }setInterval(KeepClicking,60000)\n",
        "# '''"
      ],
      "metadata": {
        "id": "HTlL9EIpnWaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Spark written in Scala programming language & requires Java Virtual Machine (JVM) to run. Therefore, download Java.\n",
        "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# # install Apache Spark with Hadoop (change the version number if needed) # https://downloads.apache.org/spark/\n",
        "# # !wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "# !wget -q http://apache.osuosl.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n",
        "# !tar xf spark-3.3.1-bin-hadoop3.tgz\n",
        "\n",
        "# # unzip the spark file to the current folder\n",
        "# # !tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "# #install findspark library using pip that will locate Spark on the system and import it as a regular library.\n",
        "# !pip install -q findspark #sparknlp\n",
        "# # set your spark folder to your system path environment. \n",
        "# import os\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# # os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop3\"\n",
        "\n",
        "# import findspark\n",
        "# findspark.init()\n",
        "# findspark.find()\n",
        "# # # OR\n",
        "# # # # #install pyspark\n",
        "# # # !pip install -q wheel\n",
        "# # # !pip install -q pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KbFvKWj9ouCN",
        "outputId": "b3ae4c41-ce8f-4451-e728-0edc04a75447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.3.1-bin-hadoop3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyspark==3.3.0 spark-nlp==4.2.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChZ4sKTqHtng",
        "outputId": "6a55994c-ab5f-4a1c-d5cb-dc7aa012cad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.4/448.4 KB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "# params =>> gpu=False\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "OeZ-mZMEH0vr",
        "outputId": "38c84f80-7fe9-4b88-8256-db56c1469ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 4.2.4\n",
            "Apache Spark version: 3.3.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fbfa570c2e0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://8669a2aa412d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd ~/.ivy2/cache/com.johnsnowlabs.nlp/spark-nlp_2.12/jars && ls -lt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zJqhjktH56p",
        "outputId": "de81d7de-1cec-439c-c46b-9ced6c781f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 43992\n",
            "-rw-r--r-- 1 root root 45044627 Nov 28 16:37 spark-nlp_2.12-4.2.4.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/DunnBC22/Spark_Projects/blob/main/Python%20(PySpark)/NLP/Sentiment%20Analysis/Sentiment%20Analysis%20of%20Reviews/Sentiment%20Analysis%20of%20Reviews.ipynb"
      ],
      "metadata": {
        "id": "aOW8v2-TJbei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import sparknlp\n",
        "# spark = sparknlp.start()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"ford_sent_classifn\").config('spark.ui.port', '4050').getOrCreate()\n",
        "#spark = SparkSession.builder.master(\"local\").appName(\"pyspark\").config('spark.ui.port', '4050').getOrCreate()\n",
        "#spark=SparkSession.builder.appName(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "print(\"Apache Spark version: \", spark.version)\n",
        "spark"
      ],
      "metadata": {
        "id": "H391qFWwBr6D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "706e46b3-c198-465f-823f-eb8a4fc53305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apache Spark version:  3.3.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fbfa570c2e0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://8669a2aa412d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Necessary Libraries\n",
        "import pandas\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "import pyspark.sql.functions as F\n",
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "1bIUiJToXVXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Ingest Data\n",
        "\n",
        "def ingest_data(file_location: str) -> pandas.DataFrame:\n",
        "    '''\n",
        "    This function ingests a single data file at a time.\n",
        "    '''\n",
        "    \n",
        "    file_type = \"csv\"\n",
        "    infer_schema = \"false\"\n",
        "    first_row_is_header = \"false\"\n",
        "    line_sep = '\\n'\n",
        "    \n",
        "    dataset = spark.read.text(file_location, lineSep=\"\\n\")\n",
        "    \n",
        "    dataset = dataset.withColumn(\"text\", F.split(dataset['value'], '\\t').getItem(0)) \\\n",
        "                    .withColumn(\"label\", F.split(dataset['value'], '\\t').getItem(1)) \\\n",
        "                    .drop(\"value\")\n",
        "    \n",
        "    return dataset\n",
        "    \n",
        "# Function to Ingest & Concatenate Multiple Files at Once\n",
        "\n",
        "def ingest_multiple_files(files: [], schema: StructType) -> pandas.DataFrame:\n",
        "    '''\n",
        "    This function concatenates multiple data files into one after calling \n",
        "    the 'ingest_data' function to ingest them individually.\n",
        "    '''\n",
        "    temp_df = spark.createDataFrame([], schema)\n",
        "    new_df = spark.createDataFrame([], schema)\n",
        "    \n",
        "    for x in files:\n",
        "        # Ingest next dataset\n",
        "        temp_df = ingest_data(x)\n",
        "        # Concatenate it to existing dataset\n",
        "        new_df = new_df.union(temp_df)\n",
        "        # unpersist the temp_df\n",
        "        temp_df.unpersist()\n",
        "    \n",
        "    return new_df\n",
        "\n",
        "# Function to Evaluate Metrics\n",
        "\n",
        "def metrics_eval(prediction: pandas.Series, label: pandas.Series, model_name: str) -> None:\n",
        "    '''\n",
        "    This function calculates and displays the following metrics:\n",
        "    - Classification Report (including accuracy, recall, precision, \n",
        "        & F1-score, among others)\n",
        "    - Confusion Matrix\n",
        "    '''\n",
        "    \n",
        "    print(\"-------------------------------------------------------------\")\n",
        "    print(f\"The {model_name} Model:\")\n",
        "    print(\"-------------------------------------------------------------\")\n",
        "    print(f\"Classification Report for the {model_name} Model:\")\n",
        "    \n",
        "    report = classification_report(label, prediction, zero_division=1)\n",
        "    print(report)\n",
        "    \n",
        "    print(\"-------------------------------------------------------------\")\n",
        "    \n",
        "    print(f\"Confusion Matrix for the {model_name} Model:\")\n",
        "    cm = confusion_matrix(label, prediction)\n",
        "    dist = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    dist.plot()\n",
        "    \n",
        "    print(\"-------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "fZ-4L0pcIuN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XdKBjPRYI0Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ingest & Preprocess Dataset\n",
        "\n",
        "file_1 = \"/content/data/amazon_cells_labelled.txt\"\n",
        "file_2 = \"/content/data/imdb_labelled.txt\"\n",
        "file_3 = \"/content/data/yelp_labelled.txt\"\n",
        "\n",
        "files_to_ingest = [file_1, file_2, file_3]\n",
        "\n",
        "orig_schema = StructType([\n",
        "    StructField(\"text\", StringType(), True),\n",
        "    StructField(\"label\", StringType(), True),\n",
        "])\n",
        "\n",
        "df = ingest_multiple_files(files_to_ingest, orig_schema)\n",
        "\n",
        "df = df.withColumn(\"text_len\", F.size(F.split(F.col('text'), ' ')))\n",
        "\n",
        "df = df.withColumn(\"label\",\\\n",
        "        F.when(df[\"label\"]==\"0\", F.regexp_replace(df[\"label\"], \"0\", \"negative\"))\\\n",
        "        .when(df[\"label\"]==\"1\", F.regexp_replace(df[\"label\"], \"1\", \"positive\")))\n",
        "\n",
        "df = df.na.drop(subset=[\"label\"])\n",
        "\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "pbE1xxSnRprO",
        "outputId": "5e50e1f6-49d2-4bce-82ee-037d11687a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[text: string, label: string, text_len: int]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Unnecessary Feature\n",
        "\n",
        "df = df.drop(\"text_len\")"
      ],
      "metadata": {
        "id": "fKWikAMDpyi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Define Pipeline Stages & Instantiate Pipeline\n",
        "# Create Pipeline Stages\n",
        "\n",
        "MODEL_NAME='sentimentdl_use_twitter'\n",
        "\n",
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"doc\")\n",
        "    \n",
        "use = UniversalSentenceEncoder.pretrained(name=\"tfhub_use\", lang=\"en\")\\\n",
        "    .setInputCols([\"doc\"])\\\n",
        "    .setOutputCol(\"use\")\n",
        "\n",
        "sent_dl_clf = SentimentDLModel.pretrained(MODEL_NAME, lang='en')\\\n",
        "    .setInputCols([\"use\"])\\\n",
        "    .setOutputCol(\"class\")"
      ],
      "metadata": {
        "id": "flzb7BVypypD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05477ba-4c1a-4fa2-cbe2-584c517e5cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n",
            "sentimentdl_use_twitter download started this may take some time.\n",
            "Approximate size to download 11.4 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Pipeline\n",
        "\n",
        "sent_dl_pipe = Pipeline().setStages([document_assembler, use, sent_dl_clf])"
      ],
      "metadata": {
        "id": "CAeXZ0L1XVdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluate Samples & Evaluate Results\n",
        "# Train & Create Predictions Using Trained Sentiment Analysis Model\n",
        "\n",
        "preds = sent_dl_pipe.fit(df).transform(df)\n",
        "     "
      ],
      "metadata": {
        "id": "-Al2B992XVgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return Condensed Predictions in Pandas DataFrame Form\n",
        "\n",
        "preds_in_pandas = (preds.select(F.col('text').alias(\"text\"), F.col('label').alias(\"ground_truth\"), F.col('class.result').alias(\"prediction\"))).toPandas()\n",
        "\n",
        "preds_in_pandas['prediction'] = preds_in_pandas['prediction'].apply(lambda x : x[0])"
      ],
      "metadata": {
        "id": "jHkumK2dXVj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display Metrics via Metrics Function Defined Above\n",
        "\n",
        "metrics_eval(preds_in_pandas['prediction'], preds_in_pandas['ground_truth'], \"Sentiment Analysis\")"
      ],
      "metadata": {
        "id": "2fWYRWcwSb6P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "fa1fabd4-657d-4275-e9fe-22d6aa26b576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------\n",
            "The Sentiment Analysis Model:\n",
            "-------------------------------------------------------------\n",
            "Classification Report for the Sentiment Analysis Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      0.80      0.81      1500\n",
            "     neutral       0.00      1.00      0.00         0\n",
            "    positive       0.83      0.81      0.82      1500\n",
            "\n",
            "    accuracy                           0.81      3000\n",
            "   macro avg       0.55      0.87      0.55      3000\n",
            "weighted avg       0.83      0.81      0.82      3000\n",
            "\n",
            "-------------------------------------------------------------\n",
            "Confusion Matrix for the Sentiment Analysis Model:\n",
            "-------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.base import LightPipeline\n",
        "light_pipeline = LightPipeline(sent_dl_pipe.fit(df))\n",
        "\n",
        "# fullannotations = light_pipeline.fullAnnotate(\"Good case, Excellent value.\")\n",
        "# print(fullannotations)\n",
        "annotations = light_pipeline.annotate(\"Good case, Excellent value.\")\n",
        "annotations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O98nYGK6StLO",
        "outputId": "164c1706-3dd3-40f2-b84e-116d0b5cb95f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'doc': ['Good case, Excellent value.'],\n",
              " 'use': ['Good case, Excellent value.'],\n",
              " 'class': ['positive']}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "light_pipeline.fullAnnotate(\"Good case, Excellent value.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRby7BpwILT_",
        "outputId": "6567fb5f-a45b-4d21-d5e0-fcd16fdb726a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'doc': [Annotation(document, 0, 26, Good case, Excellent value., {})],\n",
              "  'use': [Annotation(sentence_embeddings, 0, 26, Good case, Excellent value., {'sentence': '0', 'token': 'Good case, Excellent value.', 'pieceId': '-1', 'isWordStart': 'true'})],\n",
              "  'class': [Annotation(category, 0, 26, positive, {'sentence': '0', 'positive': '1.0', 'negative': '0.0'})]}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "light_pipeline.annotate(\"Good case, Excellent value.\")"
      ],
      "metadata": {
        "id": "h9Zw326pIWhm",
        "outputId": "8054d8f4-81bb-4dee-cb78-5a229d6a1c85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'doc': ['Good case, Excellent value.'],\n",
              " 'use': ['Good case, Excellent value.'],\n",
              " 'class': ['positive']}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#End Spark Session\n",
        "\n",
        "# spark.stop()"
      ],
      "metadata": {
        "id": "LQRx4zUhvQYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eeyVn0PIvQoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5F9B48tJS3rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# GitHub - maobedkova/TopicModelling_PySpark_SparkNLP: Tutorial for Topic Modelling using PySpark and Spark NLP\n",
        "# https://github.com/maobedkova/TopicModelling_PySpark_SparkNLP\n",
        "\n",
        "# GitHub - DunnBC22/Spark_Projects: This is the repository for all of my Spark projects, which include Spark NLP & Computer Vision projects.\n",
        "# https://github.com/DunnBC22/Spark_Projects\n",
        "\n",
        "# GitHub - prabhupavitra/Text-Summarization-PySpark: Text summarization algorithms using PySpark\n",
        "# https://github.com/prabhupavitra/Text-Summarization-PySpark\n",
        "\n",
        "# GitHub - MWFK/NLP-from-Zero-to-Hero: Compilation of NLP notebooks from various sources that address several technical challenges.\n",
        "# https://github.com/MWFK/NLP-from-Zero-to-Hero\n",
        "\n",
        "# GitHub - avisionary/reddit-comments-analysis: Big data project to analyze (Subreddit : NoStupidQuestions) comments\n",
        "# https://github.com/avisionary/reddit-comments-analysis\n",
        "\n",
        "# GitHub - SolanaO/Healthcare_SparkNLP_Study: SparkNLP and Healthcare SparkNLP based analysis of scientific literature on equine colic.\n",
        "# https://github.com/SolanaO/Healthcare_SparkNLP_Study\n",
        "\n",
        "# GitHub - martinKindall/spark_ml_and_nlp: Spark training examples of Machine Learning and Natural Language Processing, using Spark ML and Spark NLP libraries.\n",
        "# https://github.com/martinKindall/spark_ml_and_nlp\n",
        "\n",
        "# GitHub - fabiod20/big-data-analytics-and-business-intelligence: Final project of \"Big Data Analytics and Business Intelligence\" course.\n",
        "# https://github.com/fabiod20/big-data-analytics-and-business-intelligence\n",
        "\n",
        "# spark-nlp-Pyspark/spark-nlp.ipynb at master · GhaidaaShtayeh/spark-nlp-Pyspark · GitHub\n",
        "# https://github.com/GhaidaaShtayeh/spark-nlp-Pyspark/blob/master/spark-nlp.ipynb\n",
        "\n",
        "# https://github.com/josejuanmartinez/medium/blob/main/mlflow/mlflow.md\n",
        "\n",
        "# Experiment Tracking\n",
        "# https://nlp.johnsnowlabs.com/docs/en/mlflow\n",
        "# Johnsnowlabs\n",
        "# Spark NLP\n",
        "# High Performance NLP with Apache Spark\n",
        "# https://medium.com/spark-nlp/serving-spark-nlp-via-api-spring-and-lightpipelines-64d2e6413327\n",
        "\n",
        "# ATIS - Intent classification with Spark NLP | Kaggle\n",
        "# https://www.kaggle.com/code/drscarlat/atis-intent-classification-with-spark-nlp\n",
        "\n",
        "# Kaggle\n",
        "# ATIS - Intent classification with Spark NLP\n",
        "# Explore and run machine learning code with Kaggle Notebooks | Using data from ATIS Airline Travel Information System\n",
        "# NBME - Spark NLP Healthcare | Kaggle\n",
        "# https://www.kaggle.com/code/lhd0430/nbme-spark-nlp-healthcare\n",
        "\n",
        "# Kaggle\n",
        "# NBME - Spark NLP Healthcare\n",
        "# Explore and run machine learning code with Kaggle Notebooks | Using data from NBME - Score Clinical Patient Notes\n",
        "# Spark NLP via PySpark - Recognize Entities | Kaggle\n",
        "# https://www.kaggle.com/code/almogtavor/spark-nlp-via-pyspark-recognize-entities\n",
        "\n",
        "# Kaggle\n",
        "# Spark NLP via PySpark - Recognize Entities\n",
        "# Explore and run machine learning code with Kaggle Notebooks | Using data from No attached data sources\n",
        "# Universal Sentence Encoder 74% accuracy sparknlp | Kaggle\n",
        "# https://www.kaggle.com/code/nikhileswarkomati/universal-sentence-encoder-74-accuracy-sparknlp\n",
        "\n",
        "# Kaggle\n",
        "# Universal Sentence Encoder 74% accuracy sparknlp\n",
        "# Explore and run machine learning code with Kaggle Notebooks | Using data from Suicide and Depression Detection\n",
        "# https://github.com/JohnSnowLabs/spark-nlp-workshop\n",
        "\n",
        "# Spark NLP 101: LightPipeline - KDnuggets\n",
        "# https://www.kdnuggets.com/2019/11/spark-nlp-101-lightpipeline.html\n",
        "\n",
        "# John Snow Labs - Spark NLP\n",
        "# https://nlp.johnsnowlabs.com/\n",
        "\n",
        "# How to Extract Medical Information From Unstructured Data Using NLP\n",
        "# https://www.topcoder.com/thrive/articles/how-to-extract-medical-information-from-unstructured-data-using-nlp\n",
        "\n",
        "# https://www.analyticsvidhya.com/blog/2020/07/build-text-categorization-model-with-spark-nlp/\n",
        "\n",
        "# https://github.com/JohnSnowLabs/spark-nlp-models\n",
        "# https://heartbeat.comet.ml/new-integration-comet-spark-nlp-276987144d1c\n",
        "\n",
        "# https://youtu.be/jZAhLmet6Yk\n",
        "\n",
        "\n",
        "# Some major tasks of NLP are automatic summarization, discourse analysis, machine translation, conference resolution, speech recognition, etc. Automatic summarization helps the computer provide us with a summary for a specific text, article, journals, etc.\n",
        "\n",
        "# A customer support bot.\n",
        "# A language identifier.\n",
        "# An ML-powered autocomplete feature.\n",
        "# A predictive text generator.\n",
        "# A media monitor.\n",
        "\n",
        "# One of the most important and challenging tasks in the entire NLP process is to train a machine to derive the actual meaning of words, especially when the same word can have multiple meanings within a single document.\n",
        "# high demand nlp tasks"
      ],
      "metadata": {
        "id": "rT-OelAXbFks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://sparkbyexamples.com/pyspark/pyspark-aggregate-functions/\n",
        "# https://jaceklaskowski.gitbooks.io/mastering-spark-sql/content/"
      ],
      "metadata": {
        "id": "L6sT8LXC7Yi6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}